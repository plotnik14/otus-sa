# otus-monitoring
HW - Основы работы с Prometheus и Grafana  
Инструментировать сервис метриками и алертами.  
Инструментировать сервис из прошлого занятия метриками в формате Prometheus с помощью библиотеки для вашего фреймворка и ЯП.  
  
Сделать дашборд в Графане, в котором были бы метрики с разбивкой по API методам:  
1. Latency (response time) с квантилями по 0.5, 0.95, 0.99, max  
2. RPS  
3. Error Rate - количество 500ых ответов  
  
Добавить в дашборд графики с метрикам в целом по сервису, взятые с nginx-ingress-controller:  
1. Latency (response time) с квантилями по 0.5, 0.95, 0.99, max  
2. RPS  
3. Error Rate - количество 500ых ответов  
  
Настроить алертинг в графане на Error Rate и Latency.  
  
На выходе должно быть:  
1) хелм чарт или директория с манифестами для запуска приложения с нуля. В этой же директории должны быть servicemonitor-ы. В хелм чарт в качестве зависимостей не надо устанавливать nginx-ingress-controller и прометеус-оператор. Считаем, что они уже в кубике установлены.
В случае использования хелма без шаблонизации, отдельно про это написать и указать команду установки через хелм и имя релиза.  
2) в этой же директории dashboard.yaml - манифест с конфигмапом дашборды для графаны, в формате, который умеет автоматически применять prometheus-operator  
3) отдельно stresstest.yaml - манифсет с Job-ой, которая производит стабильную (не больше 20 и не меньше 5 рпс), нагрузку на все API методы, в бесконечном цикле. Для нагрузки надо делать запросы на ingress-controller, передавая значение имени сервиса, на котором живет ингресс-контроллер в переменной окружения, и в случае использования helm в качестве value-значения.  
4) скриншоты дашборды в момент стресс-тестирования сервиса. Например, после 5-10 минут нагрузки.  
  
  
Задание со звездочкой (+5 баллов)  
Инструментировать базу данных с помощью экспортера для prometheus для этой БД.  
Добавить в общий дашборд графики с метриками работы БД.  
  
Используя существующие системные метрики из кубернетеса, добавить на дашборд графики с метриками:  
1. Потребление подами приложения памяти  
2. Потребление подами приолжения CPU  
